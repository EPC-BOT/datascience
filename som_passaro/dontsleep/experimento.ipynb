{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação de Redes Neurais - Visão Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mapa mental de redes neurais\n",
    "- https://www.mindmeister.com/3493965223/deep-learning-aprendizado-profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pela lei brasileira e segurança no trânsito é proibido dirigir com sonolência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementar uma inteligência artificial \n",
    "- Criar um projeto de aplicação de redes neurais - Visão Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As tecnologias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linguagem de Programação Python\n",
    "- Biblioteca OpenCV\n",
    "- Media Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equipamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Camera 0 ou Camera 1 ou Outra Cameras\n",
    "- Camera Escolhida Logitech N231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicando as Tecnologias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A biblioteca MediaPipe - para fazer o reconhecimento da face \n",
    "- A biblioteca OpenCV - para tratar os dados visuais\n",
    "- A biblioteca NumPy - para cálculos matemáticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ead\\documents\\elias\\datascience\\som_passaro\\dontsleep\\.venv\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ead\\documents\\elias\\datascience\\som_passaro\\dontsleep\\.venv\\lib\\site-packages (from opencv-python) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip freeze >> requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.18-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting flatbuffers>=2.0 (from mediapipe)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.4.35-cp312-cp312-win_amd64.whl.metadata (1.0 kB)\n",
      "Collecting matplotlib (from mediapipe)\n",
      "  Using cached matplotlib-3.9.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting numpy<2 (from mediapipe)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
      "  Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.1-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting sentencepiece (from mediapipe)\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting ml-dtypes>=0.4.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.0-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Collecting opt-einsum (from jax->mediapipe)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting scipy>=1.10 (from jax->mediapipe)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe)\n",
      "  Using cached contourpy-1.3.0-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mediapipe)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe)\n",
      "  Using cached fonttools-4.54.1-cp312-cp312-win_amd64.whl.metadata (167 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapipe)\n",
      "  Using cached kiwisolver-1.4.7-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ead\\documents\\elias\\datascience\\som_passaro\\dontsleep\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib->mediapipe)\n",
      "  Using cached pillow-11.0.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->mediapipe)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ead\\documents\\elias\\datascience\\som_passaro\\dontsleep\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ead\\documents\\elias\\datascience\\som_passaro\\dontsleep\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Using cached mediapipe-0.10.18-cp312-cp312-win_amd64.whl (50.9 MB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached sounddevice-0.5.1-py3-none-win_amd64.whl (363 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached jax-0.4.35-py3-none-any.whl (2.2 MB)\n",
      "Using cached jaxlib-0.4.35-cp312-cp312-win_amd64.whl (56.6 MB)\n",
      "Using cached matplotlib-3.9.2-cp312-cp312-win_amd64.whl (7.8 MB)\n",
      "Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-win_amd64.whl (45.5 MB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached contourpy-1.3.0-cp312-cp312-win_amd64.whl (218 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.54.1-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.7-cp312-cp312-win_amd64.whl (55 kB)\n",
      "Using cached ml_dtypes-0.5.0-cp312-cp312-win_amd64.whl (213 kB)\n",
      "Using cached pillow-11.0.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: sentencepiece, flatbuffers, pyparsing, pycparser, protobuf, pillow, opt-einsum, numpy, kiwisolver, fonttools, cycler, attrs, absl-py, scipy, opencv-contrib-python, ml-dtypes, contourpy, CFFI, sounddevice, matplotlib, jaxlib, jax, mediapipe\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed CFFI-1.17.1 absl-py-2.1.0 attrs-24.2.0 contourpy-1.3.0 cycler-0.12.1 flatbuffers-24.3.25 fonttools-4.54.1 jax-0.4.35 jaxlib-0.4.35 kiwisolver-1.4.7 matplotlib-3.9.2 mediapipe-0.10.18 ml-dtypes-0.5.0 numpy-1.26.4 opencv-contrib-python-4.10.0.84 opt-einsum-3.4.0 pillow-11.0.0 protobuf-4.25.5 pycparser-2.22 pyparsing-3.2.0 scipy-1.14.1 sentencepiece-0.2.0 sounddevice-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O projeto é ponto de partida (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ideias inovadoras (InovaTech)\n",
    "- Implementar e sugerir novas idéias para a Industria Automobística (SENAI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.VideoCapture 000001D150CF7D10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- se você tiver mais camêras, precisa colocar o número correspondente a elas. \n",
    "- agora, vamos armazenar a saída dessa captura a uma variável que chamaremos de cap (referente a \"captura\")\n",
    "- ao utilizar a camera se atentar que as vezes temos mais de uma camera no computador, por exemplo, uma você usa para fazer uma videoconferência e a outra gravar um tela.\n",
    "- Se for apenas uma camera utilizar o valor 0\n",
    "- Se tem mais de uma colocar o número correspondente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- você lembra do while ?\n",
    "- vamos revisar?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# o while é uma estrutura de repetição (iteração) , chamada também de looping\n",
    "cont = 1\n",
    "while cont<=10:\n",
    "    print(cont)\n",
    "    cont+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usando o while, receberemos a primeira captura (inicio) \n",
    "- O objetivo é que a captura aconteça ao vivo\n",
    "- Para isso, devemos adicionar uma estrutura de repetição\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos agora aplicar o while, no nosso projeto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Códigos essenciais\n",
    "\n",
    "# while cap.isOpened() - enquanto a camera estiver aberta o while continuara rodando\n",
    "while cap.isOpened():\n",
    "    # vamos criar duas variáveis\n",
    "    \n",
    "    # SUCESSO verifica se os dados estão sendo coletados.\n",
    "            #  Ela é booleana, significa que se identificar algum vídeo ou frame, retornará verdadeiro. Se não identificar nenhum vídeo, retornará falso\n",
    "    # FRAME é uma variável frame que por sua vez, é a captura coletada pela câmera. \n",
    "\n",
    "    sucesso,frame = cap.read()  # Utilizaremos o método cap.read() para leitura\n",
    "    # agora vamos usar o if (condicional), vamos verificar se existe ou não captura acontecendo\n",
    "    # se não tivermos sucesso (booleano), queremos uma mensagem na tela - ignorando o frame vazio da camêra\n",
    "    # essa mensagem é um aviso, logo , nada esta acontecendo no nosso projeto\n",
    "    if not sucesso:\n",
    "        print('Ignorando o frame vazio da camêra')\n",
    "        continue # pesquise sobre a diferença do continue e break (história go to)\n",
    "    # depois disso, saímos do bloco condicional e podemos visualizar a captura e conferir o que está acontecendo.\n",
    "    # podemos contar com o método imshow( ) pra isso\n",
    "    # dentro dos parenteses passamos dois parâmetros 'Camera' e frame\n",
    "    # Passaremos um nome para nossa janela no formato string 'Camera'\n",
    "    # Também outro parametro - frame - definindo que o que queremos mostrar que é nosso próprio frame\n",
    "    cv2.imshow('Camera',frame)\n",
    "    # com isso, conseguiremos mostrar a imagem, mas não temos uma opção de controle para fechar a camera em tempo real.\n",
    "    # Para isso, usaremos um condicional if\n",
    "    # Ele vai pegar o laço de repetição quando apertarmos teclas específicas.\n",
    "    # Como a intenção é fechar vamos usar \"C\" de \"Close\"\n",
    "    # waitKey(10) vai esperar uma chave\n",
    "    # verificar se essa chave é c\n",
    "    # Para isso passamos & OxFF \n",
    "    \"\"\"\n",
    "      Detalhando mais\n",
    "\n",
    "      cv2.waitKey(10)\n",
    "\n",
    "            cv2.waitKey() é uma função do OpenCV\n",
    "            Que espera por uma entrada de tecla por um certo período de tempo em milissegundos\n",
    "            Passado como argumento. \n",
    "            Nesse caso, 10 indica que o programa espera 10 milissegundos.\n",
    "            Se uma tecla for pressionada durante esse tempo o código da tecla será retornado.\n",
    "            Se nenhum valor for passado, o waitKey() não bloqueia a execução e retorna -1 se nenhuma tecla for pressionada\n",
    "    \n",
    "      & 0xFF\n",
    "\n",
    "            O operador & 0xFF é uma operação de bitwise AND com 0xFF (255 em hexadecimal).\n",
    "            Isso é feito para garantir compatibilidade com sistemas operacionais diferentes.\n",
    "            Isolando o último byte do código da tecla pressionada. \n",
    "            Muitas vezes, sistemas operacionais retornam um valor de 32 bits.\n",
    "            Mas 0xFF restringe o valor à faixa de 0 a 255, que é a faixa da tabela ASCII.    \n",
    "    \n",
    "      == ord('c')\n",
    "\n",
    "           ord('c') retorna o código ASCII do caractere 'c', que é 99.\n",
    "           Esse trecho está verificando se a tecla pressionada foi 'c'. \n",
    "           Se for, a condição do if será verdadeira, permitindo que um bloco de código seja \n",
    "           executado a seguir.\n",
    "    \"\"\"\n",
    "    if cv2.waitKey(10) & 0xFF == ord('c'):\n",
    "        break\n",
    "# agora para fechar a caputura fora do if e do while\n",
    "cap.release()\n",
    "# também, vamos fechar todas as janelas/pop-ups, pois o método imshow() vai abrir um pop-up, mostrando um frame\n",
    "cv2.destroyAllWindows()\n",
    "# agora é só conectar a camera e executar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 2 - MediaPipe Face Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe' has no attribute 'solution'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# primeiro vamos importar o mediapipe\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m mp_drawing \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolution\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'mediapipe' has no attribute 'solution'"
     ]
    }
   ],
   "source": [
    "# importando mp\n",
    "import mediapipe as mp\n",
    "# primeiro vamos importar o mediapipe\n",
    "mp_drawing = mp.solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
